---
subtitle: Learn how to set up alerts in Humanloop using monitoring evaluators and webhooks.
description: This guide demonstrates how to configure automated alerts for your AI system's performance using Humanloop's monitoring capabilities.
image: https://humanloop.com/assets/docs/social-image.png
tag: draft
---

{/* WIP - for gartner /start */}

Monitoring your AI system's performance in production is crucial for maintaining quality and catching issues early. Humanloop provides tools to set up automated alerts based on your custom evaluation criteria, and guardrails to ensure that issues are prevented from happening.

## Alerting

Alerting is a critical component of any robust monitoring system. It allows you to be promptly notified of important events or issues in your Humanloop environment. By setting up alerts, you can proactively respond to potential problems and maintain the health and performance of your AI system.

Alerting in Humanloop takes advantage of the [Evaluators](/docs/v5/concepts/evaluators) you have enabled, and uses webhooks to send alerts to your preferred communication channels.

### Overview

Alerts are triggered when certain predefined conditions are met in your system. These conditions are typically monitored using log evaluators, which continuously analyze system logs and metrics.

### Use Cases for Alerting

1. **Performance Issues**

   - Use Case: Alert when API response times exceed a certain threshold.
   - Benefit: Quickly identify and address performance bottlenecks.

2. **Error Rate Spikes**

   - Use Case: Notify when the error rate for a specific service surpasses normal levels.
   - Benefit: Detect and investigate unusual error patterns promptly.

3. **Resource Utilization**

   - Use Case: Alert when CPU or memory usage approaches capacity limits.
   - Benefit: Prevent system crashes and maintain optimal performance.

4. **Security Incidents**

   - Use Case: Notify on multiple failed login attempts or unusual access patterns.
   - Benefit: Rapidly respond to potential security breaches.

5. **Data Quality Issues**

   - Use Case: Alert when incoming data doesn't meet predefined quality standards.
   - Benefit: Maintain data integrity and prevent propagation of bad data.

6. **SLA Violations**
   - Use Case: Notify when service level agreements are at risk of being breached.
   - Benefit: Proactively manage client expectations and service quality.

### Best Practices for Alerting

1. **Define Clear Thresholds**: Establish meaningful thresholds based on historical data and business requirements.
2. **Prioritize Alerts**: Categorize alerts by severity to ensure critical issues receive immediate attention.
3. **Provide Context**: Include relevant information in alerts to aid in quick diagnosis and resolution.
4. **Avoid Alert Fatigue**: Regularly review and refine alert conditions to minimize false positives.
5. **Establish Escalation Procedures**: Define clear processes for handling and escalating different types of alerts.

# Guardrails

Guardrails are protective measures implemented to prevent undesired actions or states in your Humanloop environment. They act as a safety net, automatically enforcing rules and limits to maintain system integrity.

### Overview

Guardrails typically work by setting boundaries on various system parameters and automatically taking action when these boundaries are approached or exceeded.

# How Guardrails works in Humanloop

1. set up evaluators
2. configure them as a guardrail
   - specify the type of guardrail (e.g. rate limiting, content moderation, etc.)
   - specify the threshold for the guardrail
   - specify the action to take when the guardrail is violated

### Use Cases for Guardrails

1. **Content Moderation**

   - Use Case: Automatically filter or flag inappropriate, offensive, or harmful content generated by LLMs.
   - Benefit: Maintain a safe and respectful environment for users, comply with content policies.

2. **PII Protection**

   - Use Case: Detect and redact personally identifiable information (PII) in LLM outputs.
   - Benefit: Ensure data privacy, comply with regulations like GDPR and CCPA.

3. **Bias Detection**

   - Use Case: Identify and mitigate biased language or unfair treatment in LLM responses.
   - Benefit: Promote fairness and inclusivity, reduce discriminatory outputs.

4. **Fairness Assurance**

   - Use Case: Ensure equal treatment and representation across different demographic groups in LLM interactions.
   - Benefit: Maintain ethical AI practices, avoid reinforcing societal biases.

5. **Toxicity Filtering**

   - Use Case: Detect and prevent the generation of toxic, abusive, or hateful content.
   - Benefit: Create a positive user experience, protect brand reputation.

6. **Hallucination Protections**
   - Use Case: Detect and prevent the generation of false or fabricated information by the LLM.
   - Benefit: Ensure output reliability, maintain user trust, and avoid potential misinformation spread.

### Best Practices for Implementing Guardrails

1. **Start Conservative**: Begin with more restrictive guardrails and loosen them as you gain confidence.
2. **Monitor Guardrail Actions**: Keep track of when and why guardrails are triggered to identify patterns.
3. **Regular Reviews**: Periodically assess the effectiveness of your guardrails and adjust as needed.
4. **Provide Override Mechanisms**: Allow authorized personnel to bypass guardrails in controlled situations.
5. **Document Thoroughly**: Maintain clear documentation of all implemented guardrails for team awareness.

{/* WIP - for gartner /end */}
