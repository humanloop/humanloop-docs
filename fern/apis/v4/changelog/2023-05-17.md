## Improved Python SDK

We've just released a new version of our Python SDK supporting our v4 API!

This brings support for:

- ðŸ’¬ Chat mode `humanloop.chat(...)`
- ðŸ“¥ Streaming support `humanloop.chat_stream(...)`
- ðŸ•Ÿ Async methods `humanloop.acomplete(...)`

[https://pypi.org/project/humanloop/](https://pypi.org/project/humanloop/)

### Installation

`pip install --upgrade humanloop`

### Example usage

```python
complete_response = humanloop.complete(
  project="sdk-example",
  inputs={
    "text": "Llamas that are well-socialized and trained to halter and lead after weaning and are very friendly and pleasant to be around. They are extremely curious and most will approach people easily. However, llamas that are bottle-fed or over-socialized and over-handled as youth will become extremely difficult to handle when mature, when they will begin to treat humans as they treat each other, which is characterized by bouts of spitting, kicking and neck wrestling.[33]",
  },
  model_config={
    "model": "gpt-3.5-turbo",
    "max_tokens": -1,
    "temperature": 0.7,
    "prompt_template": "Summarize this for a second-grade student:\n\nText:\n{{text}}\n\nSummary:\n",
  },
  stream=False,
)
pprint(complete_response)
pprint(complete_response.project_id)
pprint(complete_response.data[0])
pprint(complete_response.provider_responses)
```

### Migration from `0.3.x`

For those coming from an older SDK version, this introduces some breaking changes. A brief highlight of the changes:

- The client initialization step of `hl.init(...)` is now `humanloop = Humanloop(...)`.
  - Previously `provider_api_keys` could be provided in `hl.init(...)`. They should now be provided when constructing `Humanloop(...)` client.
  - ```python
    humanloop = Humanloop(
        api_key="YOUR_API_KEY",
        openai_api_key="YOUR_OPENAI_API_KEY",
        anthropic_api_key="YOUR_ANTHROPIC_API_KEY",
    )
    ```
- `hl.generate(...)`'s various call signatures have now been split into individual methods for clarity. The main ones are:
  - `humanloop.complete(project, model_config={...}, ...)` for a completion with the specified model config parameters.
  - `humanloop.complete_deployed(project, ...)` for a completion with the project's active deployment.
