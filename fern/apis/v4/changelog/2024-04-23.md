## Llama 3

[Llama 3](https://llama.meta.com/llama3/), Meta AI's latest openly-accessible model, can now be used in the Humanloop Prompt Editor. 

Llama 3 comes in two variants: an 8-billion parameter model that performs similarly to their previous 70-billion parameter Llama 2 model, and a new 70-billion parameter model. Both of these variants have an expanded context window of 8192 tokens. 

More details and benchmarks against other models can be found on their [blog post](https://ai.meta.com/blog/meta-llama-3/) and [model card](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md).

Humanloop supports Llama 3 on the Replicate model provider, and on the newly-introduced Groq model provider.

[block:image]
{
  "images": [
    {
      "image": [
        "https://files.readme.io/b0da85d-Isolated_image_3.png",
        "",
        ""
      ],
      "align": "center",
      "sizing": "813px"
    }
  ]
}
[/block]