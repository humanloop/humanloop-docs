## Evals Comparison Mode

We've added Comparison Mode to the Evals page. Comparison Mode enables Domain Experts to view multiple outputs side-by-side and annotate generations with easy-to-use controls. 

![Comparison Mode in Evals](../assets/images/changelogs/evals_comparison_mode.png)

With this update, we bring more power to AI teams and domain experts to evaluate the performance of AI features â€” a crucial part of shipping reliable applications.
To start using Comparison Mode, choose a File and click on the Evaluations submenu. Select the evaluation you want to view and navigate to the Review tab.
